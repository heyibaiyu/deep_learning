{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9159905783826223,
  "eval_steps": 500,
  "global_step": 7000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01308557969118032,
      "grad_norm": 96.53386688232422,
      "learning_rate": 3.96e-07,
      "logits/chosen": -23.521381378173828,
      "logits/rejected": -23.656658172607422,
      "logps/chosen": -670.5242309570312,
      "logps/rejected": -595.68603515625,
      "loss": 0.6962,
      "rewards/accuracies": 0.5049999952316284,
      "rewards/chosen": 0.044581275433301926,
      "rewards/margins": -0.0015166825614869595,
      "rewards/rejected": 0.046097949147224426,
      "step": 100
    },
    {
      "epoch": 0.02617115938236064,
      "grad_norm": 115.85736846923828,
      "learning_rate": 7.96e-07,
      "logits/chosen": -23.393238067626953,
      "logits/rejected": -23.412826538085938,
      "logps/chosen": -645.2113647460938,
      "logps/rejected": -577.3128051757812,
      "loss": 0.6891,
      "rewards/accuracies": 0.5350000262260437,
      "rewards/chosen": 0.20477479696273804,
      "rewards/margins": 0.022064080461859703,
      "rewards/rejected": 0.18271072208881378,
      "step": 200
    },
    {
      "epoch": 0.03925673907354096,
      "grad_norm": 74.89584350585938,
      "learning_rate": 1.1959999999999999e-06,
      "logits/chosen": -23.271228790283203,
      "logits/rejected": -23.580333709716797,
      "logps/chosen": -639.124755859375,
      "logps/rejected": -584.6951293945312,
      "loss": 0.6798,
      "rewards/accuracies": 0.5699999928474426,
      "rewards/chosen": 0.2582138478755951,
      "rewards/margins": 0.04967731609940529,
      "rewards/rejected": 0.20853649079799652,
      "step": 300
    },
    {
      "epoch": 0.05234231876472128,
      "grad_norm": 65.4319076538086,
      "learning_rate": 1.596e-06,
      "logits/chosen": -23.325237274169922,
      "logits/rejected": -23.3913631439209,
      "logps/chosen": -641.3672485351562,
      "logps/rejected": -561.099365234375,
      "loss": 0.6682,
      "rewards/accuracies": 0.5962499976158142,
      "rewards/chosen": 0.4664490222930908,
      "rewards/margins": 0.10417819023132324,
      "rewards/rejected": 0.36227086186408997,
      "step": 400
    },
    {
      "epoch": 0.06542789845590159,
      "grad_norm": 50.50223159790039,
      "learning_rate": 1.996e-06,
      "logits/chosen": -23.413856506347656,
      "logits/rejected": -23.677322387695312,
      "logps/chosen": -635.0769653320312,
      "logps/rejected": -583.609619140625,
      "loss": 0.6542,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.44226717948913574,
      "rewards/margins": 0.14134018123149872,
      "rewards/rejected": 0.30092698335647583,
      "step": 500
    },
    {
      "epoch": 0.07851347814708191,
      "grad_norm": 46.42459487915039,
      "learning_rate": 1.998855461084408e-06,
      "logits/chosen": -23.168258666992188,
      "logits/rejected": -23.368501663208008,
      "logps/chosen": -665.8711547851562,
      "logps/rejected": -568.6807250976562,
      "loss": 0.6551,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": 0.6517797112464905,
      "rewards/margins": 0.2086845338344574,
      "rewards/rejected": 0.44309520721435547,
      "step": 600
    },
    {
      "epoch": 0.09159905783826224,
      "grad_norm": 87.0718002319336,
      "learning_rate": 1.9953781657571885e-06,
      "logits/chosen": -23.312955856323242,
      "logits/rejected": -23.367328643798828,
      "logps/chosen": -688.211181640625,
      "logps/rejected": -616.705810546875,
      "loss": 0.6549,
      "rewards/accuracies": 0.5924999713897705,
      "rewards/chosen": 0.45395389199256897,
      "rewards/margins": 0.18951115012168884,
      "rewards/rejected": 0.2644427418708801,
      "step": 700
    },
    {
      "epoch": 0.10468463752944256,
      "grad_norm": 84.72058868408203,
      "learning_rate": 1.9895761186026508e-06,
      "logits/chosen": -23.29254722595215,
      "logits/rejected": -23.42302703857422,
      "logps/chosen": -656.651611328125,
      "logps/rejected": -588.540283203125,
      "loss": 0.6572,
      "rewards/accuracies": 0.5987499952316284,
      "rewards/chosen": 0.49495330452919006,
      "rewards/margins": 0.20426294207572937,
      "rewards/rejected": 0.2906903624534607,
      "step": 800
    },
    {
      "epoch": 0.11777021722062288,
      "grad_norm": 95.52798461914062,
      "learning_rate": 1.981462870570764e-06,
      "logits/chosen": -23.512338638305664,
      "logits/rejected": -23.811119079589844,
      "logps/chosen": -670.7379760742188,
      "logps/rejected": -584.6237182617188,
      "loss": 0.6322,
      "rewards/accuracies": 0.6524999737739563,
      "rewards/chosen": 0.6942495107650757,
      "rewards/margins": 0.28118640184402466,
      "rewards/rejected": 0.4130631387233734,
      "step": 900
    },
    {
      "epoch": 0.13085579691180318,
      "grad_norm": 90.13768005371094,
      "learning_rate": 1.9710573705282367e-06,
      "logits/chosen": -23.278051376342773,
      "logits/rejected": -23.449460983276367,
      "logps/chosen": -674.9119262695312,
      "logps/rejected": -564.059326171875,
      "loss": 0.6148,
      "rewards/accuracies": 0.6675000190734863,
      "rewards/chosen": 0.8825852274894714,
      "rewards/margins": 0.3921741545200348,
      "rewards/rejected": 0.49041110277175903,
      "step": 1000
    },
    {
      "epoch": 0.1439413766029835,
      "grad_norm": 125.20707702636719,
      "learning_rate": 1.9583839210025608e-06,
      "logits/chosen": -23.105186462402344,
      "logits/rejected": -23.450063705444336,
      "logps/chosen": -645.5035400390625,
      "logps/rejected": -589.3442993164062,
      "loss": 0.6751,
      "rewards/accuracies": 0.6349999904632568,
      "rewards/chosen": 0.45572176575660706,
      "rewards/margins": 0.2149161398410797,
      "rewards/rejected": 0.24080562591552734,
      "step": 1100
    },
    {
      "epoch": 0.15702695629416383,
      "grad_norm": 74.0159683227539,
      "learning_rate": 1.9434721214223316e-06,
      "logits/chosen": -23.206403732299805,
      "logits/rejected": -23.317346572875977,
      "logps/chosen": -635.9891967773438,
      "logps/rejected": -557.1542358398438,
      "loss": 0.6364,
      "rewards/accuracies": 0.6387500166893005,
      "rewards/chosen": 0.8410248756408691,
      "rewards/margins": 0.31028199195861816,
      "rewards/rejected": 0.5307428240776062,
      "step": 1200
    },
    {
      "epoch": 0.17011253598534415,
      "grad_norm": 80.12445068359375,
      "learning_rate": 1.926356798986413e-06,
      "logits/chosen": -23.32900619506836,
      "logits/rejected": -23.388837814331055,
      "logps/chosen": -649.3411865234375,
      "logps/rejected": -578.1427612304688,
      "loss": 0.6499,
      "rewards/accuracies": 0.6299999952316284,
      "rewards/chosen": 0.5130987167358398,
      "rewards/margins": 0.253055214881897,
      "rewards/rejected": 0.26004350185394287,
      "step": 1300
    },
    {
      "epoch": 0.18319811567652447,
      "grad_norm": 101.12190246582031,
      "learning_rate": 1.9070779273233978e-06,
      "logits/chosen": -23.246417999267578,
      "logits/rejected": -23.327163696289062,
      "logps/chosen": -639.154052734375,
      "logps/rejected": -594.5416870117188,
      "loss": 0.6514,
      "rewards/accuracies": 0.6287500262260437,
      "rewards/chosen": 0.5182053446769714,
      "rewards/margins": 0.24473722279071808,
      "rewards/rejected": 0.27346810698509216,
      "step": 1400
    },
    {
      "epoch": 0.1962836953677048,
      "grad_norm": 52.13147735595703,
      "learning_rate": 1.8856805331313486e-06,
      "logits/chosen": -23.252355575561523,
      "logits/rejected": -23.334604263305664,
      "logps/chosen": -675.6838989257812,
      "logps/rejected": -606.8795776367188,
      "loss": 0.645,
      "rewards/accuracies": 0.6237499713897705,
      "rewards/chosen": 0.7537376284599304,
      "rewards/margins": 0.2716842293739319,
      "rewards/rejected": 0.4820534586906433,
      "step": 1500
    },
    {
      "epoch": 0.2093692750588851,
      "grad_norm": 69.65286254882812,
      "learning_rate": 1.8622145910158565e-06,
      "logits/chosen": -22.867271423339844,
      "logits/rejected": -23.39175033569336,
      "logps/chosen": -646.7743530273438,
      "logps/rejected": -571.8292846679688,
      "loss": 0.6203,
      "rewards/accuracies": 0.6537500023841858,
      "rewards/chosen": 0.8644106388092041,
      "rewards/margins": 0.3737798035144806,
      "rewards/rejected": 0.4906308054924011,
      "step": 1600
    },
    {
      "epoch": 0.22245485475006543,
      "grad_norm": 73.30635833740234,
      "learning_rate": 1.8367349067720347e-06,
      "logits/chosen": -23.32227325439453,
      "logits/rejected": -23.527803421020508,
      "logps/chosen": -647.8767700195312,
      "logps/rejected": -580.9488525390625,
      "loss": 0.6358,
      "rewards/accuracies": 0.6362500190734863,
      "rewards/chosen": 0.9442384839057922,
      "rewards/margins": 0.359198659658432,
      "rewards/rejected": 0.5850397348403931,
      "step": 1700
    },
    {
      "epoch": 0.23554043444124576,
      "grad_norm": 88.7845230102539,
      "learning_rate": 1.8093009893830447e-06,
      "logits/chosen": -23.23614501953125,
      "logits/rejected": -23.31946563720703,
      "logps/chosen": -659.0579833984375,
      "logps/rejected": -601.87939453125,
      "loss": 0.6198,
      "rewards/accuracies": 0.668749988079071,
      "rewards/chosen": 0.7463011741638184,
      "rewards/margins": 0.3580913841724396,
      "rewards/rejected": 0.3882097899913788,
      "step": 1800
    },
    {
      "epoch": 0.24862601413242608,
      "grad_norm": 112.68744659423828,
      "learning_rate": 1.7799769120341085e-06,
      "logits/chosen": -23.235580444335938,
      "logits/rejected": -23.344100952148438,
      "logps/chosen": -664.6251831054688,
      "logps/rejected": -605.8425903320312,
      "loss": 0.6366,
      "rewards/accuracies": 0.6312500238418579,
      "rewards/chosen": 0.698190450668335,
      "rewards/margins": 0.3000868558883667,
      "rewards/rejected": 0.39810362458229065,
      "step": 1900
    },
    {
      "epoch": 0.26171159382360637,
      "grad_norm": 94.57303619384766,
      "learning_rate": 1.7488311624666161e-06,
      "logits/chosen": -23.379255294799805,
      "logits/rejected": -23.58184242248535,
      "logps/chosen": -659.2722778320312,
      "logps/rejected": -583.3308715820312,
      "loss": 0.6224,
      "rewards/accuracies": 0.6575000286102295,
      "rewards/chosen": 1.0485377311706543,
      "rewards/margins": 0.40945231914520264,
      "rewards/rejected": 0.6390855312347412,
      "step": 2000
    },
    {
      "epoch": 0.2747971735147867,
      "grad_norm": 80.63237762451172,
      "learning_rate": 1.715936483021831e-06,
      "logits/chosen": -23.446006774902344,
      "logits/rejected": -23.528539657592773,
      "logps/chosen": -657.6617431640625,
      "logps/rejected": -600.4586181640625,
      "loss": 0.6221,
      "rewards/accuracies": 0.6637499928474426,
      "rewards/chosen": 0.8667809963226318,
      "rewards/margins": 0.4314585030078888,
      "rewards/rejected": 0.43532249331474304,
      "step": 2100
    },
    {
      "epoch": 0.287882753205967,
      "grad_norm": 116.7867431640625,
      "learning_rate": 1.6813697007477834e-06,
      "logits/chosen": -23.001047134399414,
      "logits/rejected": -23.271289825439453,
      "logps/chosen": -627.1043090820312,
      "logps/rejected": -566.167724609375,
      "loss": 0.6488,
      "rewards/accuracies": 0.6362500190734863,
      "rewards/chosen": 0.6756858229637146,
      "rewards/margins": 0.32926276326179504,
      "rewards/rejected": 0.34642302989959717,
      "step": 2200
    },
    {
      "epoch": 0.30096833289714736,
      "grad_norm": 54.411529541015625,
      "learning_rate": 1.6452115479661378e-06,
      "logits/chosen": -23.22992706298828,
      "logits/rejected": -23.4884090423584,
      "logps/chosen": -659.0033569335938,
      "logps/rejected": -586.5991821289062,
      "loss": 0.6346,
      "rewards/accuracies": 0.6600000262260437,
      "rewards/chosen": 0.8295314908027649,
      "rewards/margins": 0.3756549060344696,
      "rewards/rejected": 0.4538765847682953,
      "step": 2300
    },
    {
      "epoch": 0.31405391258832765,
      "grad_norm": 66.72679138183594,
      "learning_rate": 1.6075464737181168e-06,
      "logits/chosen": -23.3094539642334,
      "logits/rejected": -23.47008514404297,
      "logps/chosen": -654.07080078125,
      "logps/rejected": -585.5274658203125,
      "loss": 0.653,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.6573023200035095,
      "rewards/margins": 0.3112547695636749,
      "rewards/rejected": 0.34604763984680176,
      "step": 2400
    },
    {
      "epoch": 0.327139492279508,
      "grad_norm": 53.939144134521484,
      "learning_rate": 1.56846244652985e-06,
      "logits/chosen": -23.413715362548828,
      "logits/rejected": -23.566518783569336,
      "logps/chosen": -688.9429931640625,
      "logps/rejected": -589.1338500976562,
      "loss": 0.609,
      "rewards/accuracies": 0.6862499713897705,
      "rewards/chosen": 1.0313421487808228,
      "rewards/margins": 0.4366074800491333,
      "rewards/rejected": 0.5947346687316895,
      "step": 2500
    },
    {
      "epoch": 0.3402250719706883,
      "grad_norm": 69.3936996459961,
      "learning_rate": 1.5280507489578084e-06,
      "logits/chosen": -23.147689819335938,
      "logits/rejected": -23.347822189331055,
      "logps/chosen": -657.7107543945312,
      "logps/rejected": -572.2144775390625,
      "loss": 0.6137,
      "rewards/accuracies": 0.6737499833106995,
      "rewards/chosen": 0.9523017406463623,
      "rewards/margins": 0.4615950286388397,
      "rewards/rejected": 0.4907067120075226,
      "step": 2600
    },
    {
      "epoch": 0.35331065166186865,
      "grad_norm": 40.230525970458984,
      "learning_rate": 1.4864057643941613e-06,
      "logits/chosen": -23.2039794921875,
      "logits/rejected": -23.305530548095703,
      "logps/chosen": -659.63134765625,
      "logps/rejected": -562.6314697265625,
      "loss": 0.6204,
      "rewards/accuracies": 0.6587499976158142,
      "rewards/chosen": 1.048413872718811,
      "rewards/margins": 0.4463388919830322,
      "rewards/rejected": 0.6020750403404236,
      "step": 2700
    },
    {
      "epoch": 0.36639623135304894,
      "grad_norm": 75.08210754394531,
      "learning_rate": 1.443624756629992e-06,
      "logits/chosen": -23.186433792114258,
      "logits/rejected": -23.24071502685547,
      "logps/chosen": -660.7488403320312,
      "logps/rejected": -579.6996459960938,
      "loss": 0.622,
      "rewards/accuracies": 0.6512500047683716,
      "rewards/chosen": 0.9580708146095276,
      "rewards/margins": 0.4262581169605255,
      "rewards/rejected": 0.5318126678466797,
      "step": 2800
    },
    {
      "epoch": 0.37948181104422923,
      "grad_norm": 79.52460479736328,
      "learning_rate": 1.3998076426912059e-06,
      "logits/chosen": -23.245994567871094,
      "logits/rejected": -23.36941909790039,
      "logps/chosen": -662.78564453125,
      "logps/rejected": -574.3766479492188,
      "loss": 0.6005,
      "rewards/accuracies": 0.6587499976158142,
      "rewards/chosen": 0.8932857513427734,
      "rewards/margins": 0.47080641984939575,
      "rewards/rejected": 0.4224793314933777,
      "step": 2900
    },
    {
      "epoch": 0.3925673907354096,
      "grad_norm": 63.1554069519043,
      "learning_rate": 1.3550567594776892e-06,
      "logits/chosen": -22.82187271118164,
      "logits/rejected": -22.933095932006836,
      "logps/chosen": -654.4795532226562,
      "logps/rejected": -585.8242797851562,
      "loss": 0.6251,
      "rewards/accuracies": 0.65625,
      "rewards/chosen": 0.8271989226341248,
      "rewards/margins": 0.3943184018135071,
      "rewards/rejected": 0.4328804314136505,
      "step": 3000
    },
    {
      "epoch": 0.4056529704265899,
      "grad_norm": 46.603694915771484,
      "learning_rate": 1.309476624750734e-06,
      "logits/chosen": -23.249500274658203,
      "logits/rejected": -23.458959579467773,
      "logps/chosen": -608.128173828125,
      "logps/rejected": -564.7974853515625,
      "loss": 0.652,
      "rewards/accuracies": 0.6349999904632568,
      "rewards/chosen": 0.7087777853012085,
      "rewards/margins": 0.31386515498161316,
      "rewards/rejected": 0.39491257071495056,
      "step": 3100
    },
    {
      "epoch": 0.4187385501177702,
      "grad_norm": 69.5566635131836,
      "learning_rate": 1.2631736930269668e-06,
      "logits/chosen": -23.042945861816406,
      "logits/rejected": -23.138412475585938,
      "logps/chosen": -669.0072021484375,
      "logps/rejected": -587.3277587890625,
      "loss": 0.6165,
      "rewards/accuracies": 0.6862499713897705,
      "rewards/chosen": 0.7838372588157654,
      "rewards/margins": 0.43505188822746277,
      "rewards/rejected": 0.348785400390625,
      "step": 3200
    },
    {
      "epoch": 0.4318241298089505,
      "grad_norm": 74.31394958496094,
      "learning_rate": 1.216256106948891e-06,
      "logits/chosen": -23.065744400024414,
      "logits/rejected": -23.26592254638672,
      "logps/chosen": -646.0935668945312,
      "logps/rejected": -609.99951171875,
      "loss": 0.6142,
      "rewards/accuracies": 0.6675000190734863,
      "rewards/chosen": 0.7499125599861145,
      "rewards/margins": 0.39425647258758545,
      "rewards/rejected": 0.3556560277938843,
      "step": 3300
    },
    {
      "epoch": 0.44490970950013087,
      "grad_norm": 55.005855560302734,
      "learning_rate": 1.1688334447127337e-06,
      "logits/chosen": -23.000383377075195,
      "logits/rejected": -23.10821533203125,
      "logps/chosen": -644.1599731445312,
      "logps/rejected": -609.9505615234375,
      "loss": 0.6347,
      "rewards/accuracies": 0.6474999785423279,
      "rewards/chosen": 0.6280256509780884,
      "rewards/margins": 0.3956451117992401,
      "rewards/rejected": 0.23238052427768707,
      "step": 3400
    },
    {
      "epoch": 0.45799528919131116,
      "grad_norm": 35.98020553588867,
      "learning_rate": 1.121016464143494e-06,
      "logits/chosen": -23.127470016479492,
      "logits/rejected": -23.392858505249023,
      "logps/chosen": -671.6954956054688,
      "logps/rejected": -602.8467407226562,
      "loss": 0.6149,
      "rewards/accuracies": 0.6787499785423279,
      "rewards/chosen": 0.6029930710792542,
      "rewards/margins": 0.4378471076488495,
      "rewards/rejected": 0.16514594852924347,
      "step": 3500
    },
    {
      "epoch": 0.4710808688824915,
      "grad_norm": 47.892311096191406,
      "learning_rate": 1.0729168440149074e-06,
      "logits/chosen": -23.220565795898438,
      "logits/rejected": -23.329038619995117,
      "logps/chosen": -673.6431274414062,
      "logps/rejected": -588.7567749023438,
      "loss": 0.6275,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.9711556434631348,
      "rewards/margins": 0.43158504366874695,
      "rewards/rejected": 0.5395705699920654,
      "step": 3600
    },
    {
      "epoch": 0.4841664485736718,
      "grad_norm": 113.90778350830078,
      "learning_rate": 1.0246469232184966e-06,
      "logits/chosen": -23.36029815673828,
      "logits/rejected": -23.406089782714844,
      "logps/chosen": -688.1880493164062,
      "logps/rejected": -619.59814453125,
      "loss": 0.6337,
      "rewards/accuracies": 0.6537500023841858,
      "rewards/chosen": 1.001620888710022,
      "rewards/margins": 0.42645150423049927,
      "rewards/rejected": 0.5751693248748779,
      "step": 3700
    },
    {
      "epoch": 0.49725202826485215,
      "grad_norm": 70.49932098388672,
      "learning_rate": 9.763194383908857e-07,
      "logits/chosen": -23.143875122070312,
      "logits/rejected": -23.361003875732422,
      "logps/chosen": -630.46435546875,
      "logps/rejected": -569.681640625,
      "loss": 0.6174,
      "rewards/accuracies": 0.6650000214576721,
      "rewards/chosen": 0.7263229489326477,
      "rewards/margins": 0.4473685920238495,
      "rewards/rejected": 0.2789543867111206,
      "step": 3800
    },
    {
      "epoch": 0.5103376079560324,
      "grad_norm": 55.55754470825195,
      "learning_rate": 9.280472606121592e-07,
      "logits/chosen": -23.186616897583008,
      "logits/rejected": -23.213315963745117,
      "logps/chosen": -651.2108154296875,
      "logps/rejected": -577.1818237304688,
      "loss": 0.6585,
      "rewards/accuracies": 0.6449999809265137,
      "rewards/chosen": 0.8490649461746216,
      "rewards/margins": 0.3576824963092804,
      "rewards/rejected": 0.4913824200630188,
      "step": 3900
    },
    {
      "epoch": 0.5234231876472127,
      "grad_norm": 771.5338745117188,
      "learning_rate": 8.799431317902288e-07,
      "logits/chosen": -22.848310470581055,
      "logits/rejected": -23.00530433654785,
      "logps/chosen": -649.569091796875,
      "logps/rejected": -581.1096801757812,
      "loss": 0.6468,
      "rewards/accuracies": 0.6600000262260437,
      "rewards/chosen": 0.8883571624755859,
      "rewards/margins": 0.3856385350227356,
      "rewards/rejected": 0.5027186870574951,
      "step": 4000
    },
    {
      "epoch": 0.5365087673383931,
      "grad_norm": 89.60579681396484,
      "learning_rate": 8.321194013468784e-07,
      "logits/chosen": -23.235536575317383,
      "logits/rejected": -23.27682113647461,
      "logps/chosen": -693.99267578125,
      "logps/rejected": -630.1317749023438,
      "loss": 0.6419,
      "rewards/accuracies": 0.6362500190734863,
      "rewards/chosen": 0.8983976244926453,
      "rewards/margins": 0.3959411680698395,
      "rewards/rejected": 0.5024564862251282,
      "step": 4100
    },
    {
      "epoch": 0.5495943470295734,
      "grad_norm": 126.92279052734375,
      "learning_rate": 7.846877638204885e-07,
      "logits/chosen": -23.012510299682617,
      "logits/rejected": -23.220582962036133,
      "logps/chosen": -660.6133422851562,
      "logps/rejected": -589.4706420898438,
      "loss": 0.6057,
      "rewards/accuracies": 0.6837499737739563,
      "rewards/chosen": 0.8140535950660706,
      "rewards/margins": 0.48623257875442505,
      "rewards/rejected": 0.3278210163116455,
      "step": 4200
    },
    {
      "epoch": 0.5626799267207537,
      "grad_norm": 60.52937316894531,
      "learning_rate": 7.377589979982627e-07,
      "logits/chosen": -23.060325622558594,
      "logits/rejected": -23.294052124023438,
      "logps/chosen": -635.1419677734375,
      "logps/rejected": -561.3612060546875,
      "loss": 0.6061,
      "rewards/accuracies": 0.6712499856948853,
      "rewards/chosen": 0.6600900888442993,
      "rewards/margins": 0.4765535593032837,
      "rewards/rejected": 0.18353652954101562,
      "step": 4300
    },
    {
      "epoch": 0.575765506411934,
      "grad_norm": 91.19880676269531,
      "learning_rate": 6.9144270818724e-07,
      "logits/chosen": -23.236278533935547,
      "logits/rejected": -23.270729064941406,
      "logps/chosen": -648.605224609375,
      "logps/rejected": -578.7167358398438,
      "loss": 0.5881,
      "rewards/accuracies": 0.6775000095367432,
      "rewards/chosen": 0.7152056694030762,
      "rewards/margins": 0.4967150092124939,
      "rewards/rejected": 0.21849071979522705,
      "step": 4400
    },
    {
      "epoch": 0.5888510861031143,
      "grad_norm": 34.06128692626953,
      "learning_rate": 6.458470682283549e-07,
      "logits/chosen": -22.967809677124023,
      "logits/rejected": -23.184755325317383,
      "logps/chosen": -685.99951171875,
      "logps/rejected": -581.455810546875,
      "loss": 0.6044,
      "rewards/accuracies": 0.6725000143051147,
      "rewards/chosen": 0.9207580089569092,
      "rewards/margins": 0.4814061224460602,
      "rewards/rejected": 0.439351886510849,
      "step": 4500
    },
    {
      "epoch": 0.6019366657942947,
      "grad_norm": 88.26490783691406,
      "learning_rate": 6.010785688514215e-07,
      "logits/chosen": -23.11739730834961,
      "logits/rejected": -23.28595733642578,
      "logps/chosen": -648.5900268554688,
      "logps/rejected": -559.91748046875,
      "loss": 0.5989,
      "rewards/accuracies": 0.6725000143051147,
      "rewards/chosen": 0.9004306793212891,
      "rewards/margins": 0.49479401111602783,
      "rewards/rejected": 0.4056367576122284,
      "step": 4600
    },
    {
      "epoch": 0.615022245485475,
      "grad_norm": 70.75518798828125,
      "learning_rate": 5.572417689610987e-07,
      "logits/chosen": -23.192258834838867,
      "logits/rejected": -23.29024887084961,
      "logps/chosen": -661.6325073242188,
      "logps/rejected": -582.07373046875,
      "loss": 0.5988,
      "rewards/accuracies": 0.6650000214576721,
      "rewards/chosen": 0.8696876764297485,
      "rewards/margins": 0.49245700240135193,
      "rewards/rejected": 0.3772306740283966,
      "step": 4700
    },
    {
      "epoch": 0.6281078251766553,
      "grad_norm": 40.24308395385742,
      "learning_rate": 5.14439051434723e-07,
      "logits/chosen": -23.174230575561523,
      "logits/rejected": -23.494394302368164,
      "logps/chosen": -658.1537475585938,
      "logps/rejected": -577.72314453125,
      "loss": 0.6159,
      "rewards/accuracies": 0.6812499761581421,
      "rewards/chosen": 0.853394627571106,
      "rewards/margins": 0.4575623571872711,
      "rewards/rejected": 0.3958323001861572,
      "step": 4800
    },
    {
      "epoch": 0.6411934048678356,
      "grad_norm": 44.567237854003906,
      "learning_rate": 4.727703840023566e-07,
      "logits/chosen": -23.144062042236328,
      "logits/rejected": -23.330608367919922,
      "logps/chosen": -666.9525756835938,
      "logps/rejected": -610.77685546875,
      "loss": 0.5942,
      "rewards/accuracies": 0.65625,
      "rewards/chosen": 0.8445153832435608,
      "rewards/margins": 0.5098811984062195,
      "rewards/rejected": 0.3346341848373413,
      "step": 4900
    },
    {
      "epoch": 0.654278984559016,
      "grad_norm": 57.67203903198242,
      "learning_rate": 4.3233308576752014e-07,
      "logits/chosen": -23.045612335205078,
      "logits/rejected": -23.20038414001465,
      "logps/chosen": -684.6754760742188,
      "logps/rejected": -575.5072021484375,
      "loss": 0.6083,
      "rewards/accuracies": 0.6700000166893005,
      "rewards/chosen": 1.006847858428955,
      "rewards/margins": 0.5372912883758545,
      "rewards/rejected": 0.46955665946006775,
      "step": 5000
    },
    {
      "epoch": 0.6673645642501963,
      "grad_norm": 68.21927642822266,
      "learning_rate": 3.932215999139167e-07,
      "logits/chosen": -23.157062530517578,
      "logits/rejected": -23.363142013549805,
      "logps/chosen": -633.7491455078125,
      "logps/rejected": -564.2293090820312,
      "loss": 0.6213,
      "rewards/accuracies": 0.6537500023841858,
      "rewards/chosen": 0.9727432131767273,
      "rewards/margins": 0.46056702733039856,
      "rewards/rejected": 0.5121761560440063,
      "step": 5100
    },
    {
      "epoch": 0.6804501439413766,
      "grad_norm": 46.31626510620117,
      "learning_rate": 3.5552727312900223e-07,
      "logits/chosen": -22.964933395385742,
      "logits/rejected": -23.277305603027344,
      "logps/chosen": -655.074951171875,
      "logps/rejected": -613.2522583007812,
      "loss": 0.6142,
      "rewards/accuracies": 0.6662499904632568,
      "rewards/chosen": 0.8610843420028687,
      "rewards/margins": 0.4727739691734314,
      "rewards/rejected": 0.38831034302711487,
      "step": 5200
    },
    {
      "epoch": 0.6935357236325569,
      "grad_norm": 54.81216812133789,
      "learning_rate": 3.193381422595616e-07,
      "logits/chosen": -22.87186050415039,
      "logits/rejected": -23.305892944335938,
      "logps/chosen": -650.5961303710938,
      "logps/rejected": -583.8839721679688,
      "loss": 0.6271,
      "rewards/accuracies": 0.6612499952316284,
      "rewards/chosen": 0.7382588982582092,
      "rewards/margins": 0.4294589161872864,
      "rewards/rejected": 0.3087998926639557,
      "step": 5300
    },
    {
      "epoch": 0.7066213033237373,
      "grad_norm": 66.48212432861328,
      "learning_rate": 2.847387286975776e-07,
      "logits/chosen": -23.146223068237305,
      "logits/rejected": -23.39067840576172,
      "logps/chosen": -653.3780517578125,
      "logps/rejected": -596.798828125,
      "loss": 0.6376,
      "rewards/accuracies": 0.6512500047683716,
      "rewards/chosen": 0.7320994734764099,
      "rewards/margins": 0.3872639834880829,
      "rewards/rejected": 0.34483546018600464,
      "step": 5400
    },
    {
      "epoch": 0.7197068830149176,
      "grad_norm": 29.206247329711914,
      "learning_rate": 2.5180984097659916e-07,
      "logits/chosen": -23.096818923950195,
      "logits/rejected": -23.310693740844727,
      "logps/chosen": -680.2943725585938,
      "logps/rejected": -601.5283813476562,
      "loss": 0.6056,
      "rewards/accuracies": 0.6787499785423279,
      "rewards/chosen": 0.7880508303642273,
      "rewards/margins": 0.5072289109230042,
      "rewards/rejected": 0.28082191944122314,
      "step": 5500
    },
    {
      "epoch": 0.7327924627060979,
      "grad_norm": 48.14665603637695,
      "learning_rate": 2.2062838603967082e-07,
      "logits/chosen": -23.1866512298584,
      "logits/rejected": -23.369224548339844,
      "logps/chosen": -629.714111328125,
      "logps/rejected": -576.2050170898438,
      "loss": 0.6257,
      "rewards/accuracies": 0.6662499904632568,
      "rewards/chosen": 0.772071361541748,
      "rewards/margins": 0.41515395045280457,
      "rewards/rejected": 0.3569174110889435,
      "step": 5600
    },
    {
      "epoch": 0.7458780423972782,
      "grad_norm": 118.04995727539062,
      "learning_rate": 1.9126718961960054e-07,
      "logits/chosen": -23.188861846923828,
      "logits/rejected": -23.223554611206055,
      "logps/chosen": -624.2020874023438,
      "logps/rejected": -573.9006958007812,
      "loss": 0.6304,
      "rewards/accuracies": 0.6487500071525574,
      "rewards/chosen": 0.6339699625968933,
      "rewards/margins": 0.38013580441474915,
      "rewards/rejected": 0.25383421778678894,
      "step": 5700
    },
    {
      "epoch": 0.7589636220884585,
      "grad_norm": 62.84636688232422,
      "learning_rate": 1.6379482615108886e-07,
      "logits/chosen": -23.16332244873047,
      "logits/rejected": -23.315467834472656,
      "logps/chosen": -636.733154296875,
      "logps/rejected": -587.9658813476562,
      "loss": 0.6153,
      "rewards/accuracies": 0.6349999904632568,
      "rewards/chosen": 0.706093966960907,
      "rewards/margins": 0.48022183775901794,
      "rewards/rejected": 0.22587212920188904,
      "step": 5800
    },
    {
      "epoch": 0.7720492017796389,
      "grad_norm": 41.60049819946289,
      "learning_rate": 1.382754586119581e-07,
      "logits/chosen": -23.243432998657227,
      "logits/rejected": -23.357431411743164,
      "logps/chosen": -671.7149047851562,
      "logps/rejected": -605.3888549804688,
      "loss": 0.6284,
      "rewards/accuracies": 0.6449999809265137,
      "rewards/chosen": 0.8273686170578003,
      "rewards/margins": 0.4431033432483673,
      "rewards/rejected": 0.3842652440071106,
      "step": 5900
    },
    {
      "epoch": 0.7851347814708192,
      "grad_norm": 50.83759307861328,
      "learning_rate": 1.1476868866754486e-07,
      "logits/chosen": -23.173398971557617,
      "logits/rejected": -23.415414810180664,
      "logps/chosen": -651.913818359375,
      "logps/rejected": -584.0657958984375,
      "loss": 0.6142,
      "rewards/accuracies": 0.6787499785423279,
      "rewards/chosen": 0.7638042569160461,
      "rewards/margins": 0.45726722478866577,
      "rewards/rejected": 0.30653703212738037,
      "step": 6000
    },
    {
      "epoch": 0.7982203611619995,
      "grad_norm": 71.04820251464844,
      "learning_rate": 9.332941746824818e-08,
      "logits/chosen": -23.188518524169922,
      "logits/rejected": -23.431968688964844,
      "logps/chosen": -639.4360961914062,
      "logps/rejected": -551.826904296875,
      "loss": 0.6351,
      "rewards/accuracies": 0.6449999809265137,
      "rewards/chosen": 0.7782813906669617,
      "rewards/margins": 0.39335671067237854,
      "rewards/rejected": 0.3849247097969055,
      "step": 6100
    },
    {
      "epoch": 0.8113059408531798,
      "grad_norm": 91.38221740722656,
      "learning_rate": 7.40077174253505e-08,
      "logits/chosen": -23.216594696044922,
      "logits/rejected": -23.384052276611328,
      "logps/chosen": -651.3863525390625,
      "logps/rejected": -573.3947143554688,
      "loss": 0.6054,
      "rewards/accuracies": 0.6800000071525574,
      "rewards/chosen": 0.8747380971908569,
      "rewards/margins": 0.452164888381958,
      "rewards/rejected": 0.4225732386112213,
      "step": 6200
    },
    {
      "epoch": 0.8243915205443602,
      "grad_norm": 111.50628662109375,
      "learning_rate": 5.6848715264579126e-08,
      "logits/chosen": -23.373146057128906,
      "logits/rejected": -23.56414222717285,
      "logps/chosen": -646.7380981445312,
      "logps/rejected": -580.659423828125,
      "loss": 0.6079,
      "rewards/accuracies": 0.6712499856948853,
      "rewards/chosen": 0.8357547521591187,
      "rewards/margins": 0.45635780692100525,
      "rewards/rejected": 0.3793969750404358,
      "step": 6300
    },
    {
      "epoch": 0.8374771002355405,
      "grad_norm": 85.00743865966797,
      "learning_rate": 4.189248663054956e-08,
      "logits/chosen": -23.08197593688965,
      "logits/rejected": -23.190427780151367,
      "logps/chosen": -672.80712890625,
      "logps/rejected": -601.20068359375,
      "loss": 0.6171,
      "rewards/accuracies": 0.643750011920929,
      "rewards/chosen": 0.8219708204269409,
      "rewards/margins": 0.4889586567878723,
      "rewards/rejected": 0.333012193441391,
      "step": 6400
    },
    {
      "epoch": 0.8505626799267207,
      "grad_norm": 27.70130729675293,
      "learning_rate": 2.9173962488238e-08,
      "logits/chosen": -23.15530014038086,
      "logits/rejected": -23.35065269470215,
      "logps/chosen": -632.469970703125,
      "logps/rejected": -567.295654296875,
      "loss": 0.6282,
      "rewards/accuracies": 0.6524999737739563,
      "rewards/chosen": 0.795718789100647,
      "rewards/margins": 0.4236728250980377,
      "rewards/rejected": 0.37204596400260925,
      "step": 6500
    },
    {
      "epoch": 0.863648259617901,
      "grad_norm": 86.86737060546875,
      "learning_rate": 1.8722847540096565e-08,
      "logits/chosen": -23.272680282592773,
      "logits/rejected": -23.409337997436523,
      "logps/chosen": -672.5003051757812,
      "logps/rejected": -589.7745361328125,
      "loss": 0.5951,
      "rewards/accuracies": 0.6762499809265137,
      "rewards/chosen": 0.8712668418884277,
      "rewards/margins": 0.4927513897418976,
      "rewards/rejected": 0.37851542234420776,
      "step": 6600
    },
    {
      "epoch": 0.8767338393090814,
      "grad_norm": 84.78606414794922,
      "learning_rate": 1.056355084934224e-08,
      "logits/chosen": -23.136564254760742,
      "logits/rejected": -23.29205322265625,
      "logps/chosen": -642.8573608398438,
      "logps/rejected": -564.8153076171875,
      "loss": 0.5957,
      "rewards/accuracies": 0.6899999976158142,
      "rewards/chosen": 0.8683796525001526,
      "rewards/margins": 0.507027268409729,
      "rewards/rejected": 0.3613523542881012,
      "step": 6700
    },
    {
      "epoch": 0.8898194190002617,
      "grad_norm": 73.1364974975586,
      "learning_rate": 4.7151288314604134e-09,
      "logits/chosen": -23.105497360229492,
      "logits/rejected": -23.293920516967773,
      "logps/chosen": -635.28515625,
      "logps/rejected": -611.2277221679688,
      "loss": 0.6352,
      "rewards/accuracies": 0.6600000262260437,
      "rewards/chosen": 0.8303516507148743,
      "rewards/margins": 0.43365055322647095,
      "rewards/rejected": 0.39670103788375854,
      "step": 6800
    },
    {
      "epoch": 0.902904998691442,
      "grad_norm": 37.21569061279297,
      "learning_rate": 1.1912407470623387e-09,
      "logits/chosen": -23.010108947753906,
      "logits/rejected": -23.210908889770508,
      "logps/chosen": -673.9603271484375,
      "logps/rejected": -607.5042724609375,
      "loss": 0.5838,
      "rewards/accuracies": 0.6775000095367432,
      "rewards/chosen": 0.8427348136901855,
      "rewards/margins": 0.49753597378730774,
      "rewards/rejected": 0.3451988697052002,
      "step": 6900
    },
    {
      "epoch": 0.9159905783826223,
      "grad_norm": 62.203407287597656,
      "learning_rate": 1.1680004985414883e-13,
      "logits/chosen": -23.25357437133789,
      "logits/rejected": -23.336671829223633,
      "logps/chosen": -651.9158325195312,
      "logps/rejected": -568.2203979492188,
      "loss": 0.6291,
      "rewards/accuracies": 0.6537500023841858,
      "rewards/chosen": 0.8388677835464478,
      "rewards/margins": 0.43869340419769287,
      "rewards/rejected": 0.40017440915107727,
      "step": 7000
    }
  ],
  "logging_steps": 100,
  "max_steps": 7000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
